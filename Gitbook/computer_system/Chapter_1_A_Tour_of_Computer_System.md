Section 1.1  Information Is Bits + Context

Our hello program begins life as a source program (or source ﬁle) that the programmer creates with an editor and saves in a text ﬁle called hello.c. The source program is a sequence of bits, each with a value of 0 or 1, organized in 8-bit chunks called bytes. Each byte represents some text character in the program. MostmodernsystemsrepresenttextcharactersusingtheASCIIstandardthat represents each character with a unique byte-sized integer value. For example, Figure 1.2 shows the ASCII representation of the hello.c program. The hello.c program is stored in a ﬁle as a sequence of bytes. Each byte has an integer value that corresponds to some character. For example, the ﬁrst byte has the integer value 35, which corresponds to the character ‘#’. The second byte hastheintegervalue105,whichcorrespondstothecharacter‘i’,andsoon.Notice that each text line is terminated by the invisible newline character ‘\n’, which is representedbytheintegervalue10.Filessuchas hello.c thatconsistexclusively of ASCII characters are known as text ﬁles. All other ﬁles are known as binary ﬁles. Therepresentationofhello.cillustratesafundamentalidea:Allinformation in a system—including disk ﬁles, programs stored in memory, user data stored in memory,anddatatransferredacrossanetwork—isrepresentedasabunchofbits. The only thing that distinguishes different data objects is the context in which we view them. For example, in different contexts, the same sequence of bytes might represent an integer, ﬂoating-point number, character string, or machine instruction. Asprogrammers,weneedtounderstandmachinerepresentationsofnumbers because they are not the same as integers and real numbers. They are ﬁnite approximations that can behave in unexpected ways. This fundamental idea is explored in detail in Chapter 2.

Aside
Origins of the C programming languageC was developed from 1969 to 1973 by Dennis Ritchie of Bell Laboratories. The American NationalStandards Institute (ANSI) ratified the ANSI C standard in 1989, and this standardization later becamethe  responsibility  of  the  International  Standards  Organization  (ISO).  The  standards  define  the  Clanguage and a set of library functions known as theC standard library. Kernighan and Ritchie describeANSI C in their classic book, which is known affectionately as “K&R” [58]. In Ritchie’s words [88], Cis “quirky, flawed, and an enormous success.” So why the success?.C was closely tied with the Unix operating system.C was developed from the beginning as thesystem programming language for Unix. Most of the Unix kernel, and all of its supporting toolsand libraries, were written in C. As Unix became popular in universities in the late 1970s and early1980s, many people were exposed to C and found that they liked it. Since Unix was written almostentirely in C, it could be easily ported to new machines, which created an even wider audience forboth C and Unix..C is a small, simple language.The design was controlled by a single person, rather than a committee,and the result was a clean,  consistent design with little baggage. The K&R book describes thecomplete language and standard library, with numerous examples and exercises, in only 261 pages.The simplicity of C made it relatively easy to learn and to port to different computers..C was designed for a practical purpose.C was designed to implement the Unix operating system.Later, other people found that they could write the programs they wanted, without the languagegetting in the way.C  is  the  language  of  choice  for  system-level  programming,  and  there  is  a  huge  installed  base  ofapplication-level programs as well. However, it is not perfect for all programmers and all situations.C pointers are a common source of confusion and programming errors. C also lacks explicit supportfor useful abstractions such as classes, objects, and exceptions. Newer languages such as C++ and Javaaddress these issues for application-level programs

Section 1.2  Programs Are Translated by Other Programs into Different Forms

The hello program begins life as a high-level C program because it can be readand understood by human beings in that form. However, in order to runhello.con the system, the individual C statements must be translated by other programsinto a sequence of low-levelmachine-languageinstructions. These instructions arethen packaged in a form called anexecutable object programand stored as a binarydisk file. Object programs are also referred to asexecutable object files.On a Unix system, the translation from source file to object file is performedby acompiler driver:unix>gcc -o hello hello.c

Here, the gcc compiler driver reads the source filehello.cand translates it intoan  executable  object  filehello.  The  translation  is  performed  in  the  sequenceof four phases shown in Figure 1.3. The programs that perform the four phases(preprocessor,compiler,assembler,  andlinker)  are  known  collectively  as  thecompilation system..Preprocessing phase.The preprocessor (cpp) modifies the original C programaccording  to  directives  that  begin  with  the#character.  For  example,  the#include <stdio.h>command in line 1 ofhello.ctells the preprocessorto read the contents of the system header filestdio.hand insert it directlyinto the program text. The result is another C program, typically with the.isuffix..Compilation phase.The compiler (cc1) translates the text filehello.iintothe text filehello.s,  which contains anassembly-language program. Eachstatement in an assembly-language program exactly describes one low-levelmachine-language instruction in a standard text form. Assembly language isuseful because it provides a common output language for different compilersfor  different  high-level  languages.  For  example,  C  compilers  and  Fortrancompilers both generate output files in the same assembly language..Assembly phase.Next, the assembler (as) translateshello.sinto machine-language instructions, packages them in a form known as arelocatable objectprogram, and stores the result in the object filehello.o.Thehello.ofile isa binary file whose bytes encode machine language instructions rather thancharacters. If we were to viewhello.owith a text editor, it would appear tobe gibberish..Linking phase.Notice that ourhelloprogram calls theprintffunction, whichis part of thestandard C libraryprovided by every C compiler. Theprintffunction resides in a separate precompiled object file calledprintf.o, whichmust somehow be merged with ourhello.oprogram. The linker (ld) handlesthis merging. The result is thehellofile, which is anexecutable object file(orsimplyexecutable) that is ready to be loaded into memory and executed bythe system.

Aside 
The GNU projectGCCis one of many useful tools developed by the GNU (short for GNU’s Not Unix) project. TheGNU project is a tax-exempt charity started by Richard Stallman in 1984, with the ambitious goal ofdeveloping a complete Unix-like system whose source code is unencumbered by restrictions on howit can be modified or distributed. The GNU project has developed an environment with all the majorcomponents of a Unix operating system, except for the kernel, which was developed separately bythe Linux project. The GNU environment includes theemacseditor,gcccompiler,gdbdebugger,assembler,  linker,  utilities  for  manipulating  binaries,  and  other  components.  Thegcccompiler  hasgrown  to  support  many  different  languages,  with  the  ability  to  generate  code  for  many  differentmachines. Supported languages include C, C++, Fortran, Java, Pascal, Objective-C, and Ada.The GNU project is a remarkable achievement, and yet it is often overlooked. The modern open-source movement (commonly associated with Linux) owes its intellectual origins to the GNU project’snotion offree software(“free” as in “free speech,” not “free beer”). Further, Linux owes much of itspopularity to the GNU tools, which provide the environment for the Linux kernel.

Section 1.3 It Pays to Understand How Compilation Systems Work

For simple programs such ashello.c, we can rely on the compilation system toproduce correct and efficient machine code. However, there are some importantreasons why programmers need to understand how compilation systems work:.Optimizing program performance.Modern compilers are sophisticated toolsthat usually produce good code. As programmers, we do not need to knowthe inner workings of the compiler in order to write efficient code. However,in order to make good coding decisions in our C programs,  we do need abasic understanding of machine-level code and how the compiler translatesdifferent C statements into machine code. For example, is aswitchstatementalways  more  efficient  than  a  sequence  ofif-elsestatements?  How  muchoverhead is incurred by a function call? Is awhileloop more efficient thanaforloop? Are pointer references more efficient than array indexes? Whydoes our loop run so much faster if we sum into a local variable instead of anargument that is passed by reference? How can a function run faster when wesimply rearrange the parentheses in an arithmetic expression?In Chapter 3, we will introduce two related machine languages: IA32, the32-bit code that has become ubiquitous on machines running Linux, Windows,and  more  recently  the  Macintosh  operating  systems,  and  x86-64,  a  64-bitextension found in more recent microprocessors. We describe how compilerstranslate different C constructs into these languages. In Chapter 5, you willlearn how to tune the performance of your C programs by making simpletransformations  to  the  C  code  that  help  the  compiler  do  its  job  better.  InChapter 6, you will learn about the hierarchical nature of the memory system,how C compilers store data arrays in memory, and how your C programs canexploit this knowledge to run more efficiently.

Understanding link-time errors.In our experience, some of the most perplex-ing programming errors are related to the operation of the linker, especiallywhen you are trying to build large software systems. For example, what doesit mean when the linker reports that it cannot resolve a reference? What is thedifference between a static variable and a global variable? What happens ifyou define two global variables in different C files with the same name? Whatis the difference between a static library and a dynamic library? Why does itmatter what order we list libraries on the command line? And scariest of all,why do some linker-related errors not appear until run time? You will learnthe answers to these kinds of questions in Chapter 7..Avoiding security holes.For many years,buffer overflow vulnerabilitieshaveaccounted for the majority of security holes in network and Internet servers.These vulnerabilities exist because too few programmers understand the needto carefully restrict the quantity and forms of data they accept from untrustedsources. A first step in learning secure programming is to understand the con-sequences of the way data and control information are stored on the programstack.  We  cover  the  stack  discipline  and  buffer  overflow  vulnerabilities  inChapter 3 as part of our study of assembly language. We will also learn aboutmethods that can be used by the programmer, compiler, and operating systemto reduce the threat of attack.


Section 1.4  Processors Read and Interpret Instructions Stored in Memory

At this point, ourhello.csource program has been translated by the compilationsystem into an executable object file calledhellothat is stored on disk. To run the executable file on a Unix system, 
we type its name to an application programknown as a shell:
unix>./hello hello, world
unix>
The shell is a command-line interpreter that prints a prompt, waits for you to type acommand line, and then performs the command. If the first word of the commandline does not correspond to a built-in shell command, then the shell assumes thatit is the name of an executable file that it should load and run. So in this case,the shell loads and runs thehelloprogram and then waits for it to terminate. Thehelloprogram prints its message to the screen and then terminates. The shell thenprints a prompt and waits for the next input command line.

1.4.1 Hardware Organization of a System

To  understand  what  happens  to  ourhelloprogram  when  we  run  it,  we  needto understand the hardware organization of a typical system, which is shown in Figure 1.4. This particular picture is modeled after the family of Intel Pentium systems,  but  all  systems  have  a  similar  look  and  feel.  Don’t  worry  about  thecomplexity  of  this  figure  just  now.  We  will  get  to  its  various  details  in  stagesthroughout the course of the book.BusesRunning throughout the system is a collection of electrical conduits calledbusesthat carry bytes of information back and forth between the components. Busesare typically designed to transfer fixed-sized chunks of bytes known aswords.Thenumber of bytes in a word (theword size) is a fundamental system parameter thatvaries across systems. Most machines today have word sizes of either 4 bytes (32bits) or 8 bytes (64 bits). For the sake of our discussion here, we will assume a wordsize of 4 bytes, and we will assume that buses transfer only one word at a time.I/O DevicesInput/output (I/O) devices are the system’s connection to the external world. Ourexample system has four I/O devices: a keyboard and mouse for user input,  adisplay for user output, and a disk drive (or simply disk) for long-term storage ofdata and programs. Initially, the executablehelloprogram resides on the disk.Each I/O device is connected to the I/O bus by either acontrolleror anadapter.The distinction between the two is mainly one of packaging. Controllers are chipsets in the device itself or on the system’s main printed circuit board (often calledthemotherboard). An adapter is a card that plugs into a slot on the motherboard.Regardless, the purpose of each is to transfer information back and forth betweenthe I/O bus and an I/O device.

Chapter  6  has  more  to  say  about  how  I/O  devices  such  as  disks  work. In Chapter 10, you will learn how to use the Unix I/O interface to access devices fromyour application programs. We focus on the especially interesting class of devicesknown as networks, but the techniques generalize to other kinds of devices as well.Main MemoryThemain memoryis a temporary storage device that holds both a program andthe data it manipulates while the processor is executing the program. Physically,main memory consists of a collection ofdynamic random access memory(DRAM)chips. Logically, memory is organized as a linear array of bytes, each with its ownunique address (array index) starting at zero. In general,  each of the machineinstructions that constitute a program can consist of a variable number of bytes.The sizes of data items that correspond to C program variables vary according totype. For example, on an IA32 machine running Linux, data of typeshortrequirestwo bytes, typesint,float, andlongfour bytes, and typedoubleeight bytes.Chapter 6 has more to say about how memory technologies such as DRAMchips work, and how they are combined to form main memory.ProcessorThecentral processing unit(CPU), or simplyprocessor, is the engine that inter-prets (orexecutes) instructions stored in main memory. At its core is a word-sizedstorage device (orregister) called theprogram counter(PC). At any point in time,the PC points at (contains the address of) some machine-language instruction inmain memory.1From the time that power is applied to the system,  until the time that thepower is shut off, a processor repeatedly executes the instruction pointed at by theprogram counter and updates the program counter to point to the next instruction.A processorappears tooperate according to a very simple instruction executionmodel, defined by itsinstruction set architecture. In this model, instructions executein strict sequence, and executing a single instruction involves performing a seriesof  steps.  The  processor  reads  the  instruction  from  memory  pointed  at  by  theprogram counter (PC), interprets the bits in the instruction, performs some simpleoperation dictated by the instruction, and then updates the PC to point to the nextinstruction, which may or may not be contiguous in memory to the instruction thatwas just executed.There are only a few of these simple operations,  and they revolve aroundmain memory, theregister file, and thearithmetic/logic unit(ALU). The registerfile is a small storage device that consists of a collection of word-sized registers,each with its own unique name. The ALU computes new data and address values.Here are some examples of the simple operations that the CPU might carry outat the request of an instruction:

.Load:Copy a byte or a word from main memory into a register, overwritingthe previous contents of the register.

.Store:Copy a byte or a word from a register to a location in main memory,overwriting the previous contents of that location.

.Operate:Copy the contents of two registers to the ALU, perform an arithmeticoperation on the two words, and store the result in a register, overwriting theprevious contents of that register.

.Jump:Extract a word from the instruction itself and copy that word into theprogram counter (PC), overwriting the previous value of the PC.

We  say  that  a  processor  appears  to  be  a  simple  implementation  of  its  in-struction set architecture, but in fact modern processors use far more complexmechanisms to speed up program execution. Thus,  we can distinguish the pro-cessor’s instruction set architecture, describing the effect of each machine-codeinstruction, from itsmicroarchitecture, describing how the processor is actuallyimplemented. When we study machine code in Chapter 3, we will consider theabstraction provided by the machine’s instruction set architecture. Chapter 4 hasmore to say about how processors are actually implemented.

1. PC is also a commonly used acronym for “personal computer.” However, the distinction betweenthe two should be clear from the context.

1.4.2 Running the hello Program 
Given this simple view of a system’s hardware organization and operation, we canbegin to understand what happens when we run our example program. We mustomit a lot of details here that will be filled in later, but for now we will be contentwith the big picture.Initially, the shell program is executing its instructions, waiting for us to typea  command.  As  we  type  the  characters  “./hello”  at  the  keyboard,  the  shellprogram reads each one into a register, and then stores it in memory, as shown inFigure 1.5.When we hit theenterkey on the keyboard, the shell knows that we havefinished typing the command. The shell then loads the executablehellofile byexecuting a sequence of instructions that copies the code and data in thehelloobject file from disk to main memory. The data include the string of characters“hello, world\n” that will eventually be printed out.Using a technique known asdirect memory access(DMA, discussed in Chap-ter 6), the data travels directly from disk to main memory, without passing throughthe processor. This step is shown in Figure 1.6.Once the code and data in thehelloobject file are loaded into memory, theprocessor begins executing the machine-language instructions in thehellopro-gram’smainroutine. These instructions copy the bytes in the “hello, world\n”string from memory to the register file, and from there to the display device, wherethey are displayed on the screen. This step is shown in Figure 1.7.

1.5 Caches Matter
An important lesson from this simple example is that a system spends a lot oftime moving information from one place to another. The machine instructions inthehelloprogram are originally stored on disk. When the program is loaded,they are copied to main memory. As the processor runs the program,  instruc-tions are copied from main memory into the processor. Similarly, the data string“hello,world\n”, originally on disk, is copied to main memory, and then copiedfrom main memory to the display device. From a programmer’s perspective, muchof this copying is overhead that slows down the “real work” of the program. Thus,a major goal for system designers is to make these copy operations run as fast aspossible.Because of physical laws, larger storage devices are slower than smaller stor-age devices. And faster devices are more expensive to build than their slowercounterparts. For example, the disk drive on a typical system might be 1000 timeslarger than the main memory, but it might take the processor 10,000,000 timeslonger to read a word from disk than from memory.Similarly, a typical register file stores only a few hundred bytes of information,as opposed to billions of bytes in the main memory. However, the processor canread data from the register file almost 100 times faster than from memory. Evenmore troublesome, as semiconductor technology progresses over the years, thisprocessor-memory gapcontinues  to  increase.  It  is  easier  and  cheaper  to  makeprocessors run faster than it is to make main memory run faster.To  deal  with  the  processor-memory  gap,  system  designers  include  smallerfaster  storage  devices  calledcache memories(or  simply  caches)  that  serve  astemporary staging areas for information that the processor is likely to need inthe near future. Figure 1.8 shows the cache memories in a typical system. AnL1
cache on the processor chip holds tens of thousands of bytes and can be accessednearly as fast as the register file. A largerL2 cachewith hundreds of thousandsto millions of bytes is connected to the processor by a special bus. It might take 5times longer for the process to access the L2 cache than the L1 cache, but this isstill 5 to 10 times faster than accessing the main memory. The L1 and L2 caches areimplemented with a hardware technology known asstatic random access memory(SRAM). Newer and more powerful systems even have three levels of cache: L1,L2, and L3. The idea behind caching is that a system can get the effect of botha very large memory and a very fast one by exploitinglocality, the tendency forprograms to access data and code in localized regions. By setting up caches to holddata that is likely to be accessed often, we can perform most memory operationsusing the fast caches.One of the most important lessons in this book is that application program-mers who are aware of cache memories can exploit them to improve the perfor-mance of their programs by an order of magnitude. You will learn more aboutthese important devices and how to exploit them in Chapter 6.


1.6 Storage Devices Form a Hierarchy

This  notion  of  inserting  a  smaller,  faster  storage  device  (e.g.,  cache  memory)between the processor and a larger slower device (e.g., main memory) turns outto be a general idea. In fact, the storage devices in every computer system areorganized as amemory hierarchysimilar to Figure 1.9. As we move from the topof the hierarchy to the bottom, the devices become slower, larger, and less costlyper byte. The register file occupies the top level in the hierarchy, which is knownas level 0, or L0. We show three levels of caching L1 to L3, occupying memoryhierarchy levels 1 to 3. Main memory occupies level 4, and so on.The main idea of a memory hierarchy is that storage at one level serves as acache for storage at the next lower level. Thus, the register file is a cache for theL1 cache. Caches L1 and L2 are caches for L2 and L3, respectively. The L3 cacheis a cache for the main memory, which is a cache for the disk. On some networkedsystems with distributed file systems, the local disk serves as a cache for data storedon the disks of other systems.
Just as programmers can exploit knowledge of the different caches to improveperformance, programmers can exploit their understanding of the entire memoryhierarchy. Chapter 6 will have much more to say about this.






