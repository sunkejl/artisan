2.1.1
Hexadecimal Notation

A single byte consists of 8 bits. 

In binary notation, its value ranges from 00000000  to 11111111. 

When viewed as a decimal integer, its value ranges from 0 (10) to 255 (10).

Neither notation is very convenient for describing bit patterns. 

Binary notation is too verbose, while with decimal notation, 

it is tedious to convert to and from bit patterns. 

Instead, we write bit patterns as base-16, or hexadecimal numbers.

Hexadecimal (or simply “hex”) uses digits ‘0’ through ‘9’ along with characters
‘A’ through ‘F’ to represent 16 possible values. 

Figure 2.2 shows the decimal and binary values associated with the 16 hexadecimal digits. 

Written in hexadecimal, the value of a single byte can range from 00 (16) to FF (16) .

In C, numeric constants starting with 0x or 0X are interpreted as being in hexadecimal. 

The characters ‘A’ through ‘F’ may be written in either upper or lower case. 

For example, we could write the number FA1D37B (16) as 0xFA1D37B, as 0xfa1d37b, 

or even mixing upper and lower case, e.g., 0xFa1D37b. 

We will use the C notation for representing hexadecimal values in this book.

A common task in working with machine-level programs is to manually convert between decimal, binary, and hexadecimal 
representations of bit patterns.

Converting between binary and hexadecimal is straightforward, since it can be
performed one hexadecimal digit at a time. Digits can be converted by referring
to a chart such as that shown in Figure 2.2. One simple trick for doing the conver-
sion in your head is to memorize the decimal equivalents of hex digits A, C, and F.
The hex values B, D, and E can be translated to decimal by computing their values
relative to the first three.
For example, suppose you are given the number 0x173A4C. You can convert
this to binary format by expanding each hexadecimal digit, as follows: