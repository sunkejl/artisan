2.5
Summary

Computers encode information as bits, generally organized as sequences of bytes.

Different encodings are used for representing 
integers, 
real numbers, 
and character strings. 

Different models of computers use different conventions for encoding
numbers and for ordering the bytes within multi-byte data.

The C language is designed to accommodate 
a wide range of different implementations in terms of word sizes and numeric encodings. 

Most current machines have 32-bit word sizes, 
although high-end machines increasingly have 64-bit words.

Most machines use two’s-complement encoding of integers and 
IEEE encoding of floating point. 

Understanding these encodings at the bit level, 

as well as understanding the mathematical characteristics of the arithmetic operations, 

is important for writing programs that operate correctly over the full range of numeric
values.

When casting between signed and unsigned integers of the same size, most
C implementations follow the convention that the underlying bit pattern does
not change. 

On a two’s-complement machine, 
this behavior is characterized by functions T2U w and U2T w , for a w-bit value. 

The implicit casting of C gives results that many programmers do not anticipate, 
often leading to program bugs.

Due to the finite lengths of the encodings, computer arithmetic has properties
quite different from conventional integer and real arithmetic. 

The finite length can cause numbers to overflow, 
when they exceed the range of the representation.

Floating-point values can also underflow, 
when they are so close to 0.0 that they are changed to zero.

The finite integer arithmetic implemented by C, 

as well as most other programming languages, 
has some peculiar properties compared to true integer arithmetic. 

For example, the expression x*x can evaluate to a negative number due to overflow. 

Nonetheless, both unsigned and two’s-complement arithmetic satisfy
many of the other properties of integer arithmetic, 

including 
associativity, 
commutativity, 
and distributivity. 

This allows compilers to do many optimizations. 

We have seen several clever ways to 
exploit combinations of bit-level operations and arithmetic operations. 
For example, we saw that with two’s-complement
arithmetic ~x+1 is equivalent to -x. 

As another example, suppose we want a bit
pattern of the form [0, . . . , 0, 1, . . . , 1], consisting of w − k zeros followed by k
ones. 

Such bit patterns are useful for masking operations. 
This pattern can be generated by the C expression (1<<k)-1, 


Floating-point representations approximate real numbers by encoding numbers of 
the form x * 2^y . 

The most common floating-point representation is defined
by IEEE Standard 754. 

It provides for several different precisions, 
with the most common being single (32 bits) and double (64 bits). 

IEEE floating point also has
representations for special values representing plus and minus infinity, 
as well as not-a-number.

Floating-point arithmetic must be used very carefully, because it has only
limited range and precision, and because it does not obey common mathematical
properties such as associativity.











































































enerate the bit pattern 0xFF.