2.1.4
Addressing and Byte Ordering

For program objects that span multiple bytes, 

we must establish two conventions:

what the address of the object will be, and how we will order the bytes in memory.

In virtually all machines, a multi-byte object is stored as a contiguous sequence of bytes, 

with the address of the object given by the smallest address of the bytes used. 

For example, suppose a variable x of type int has address 0x100, that is, 

the value of the address expression &x is 0x100. 

Then the 4 bytes of x would be stored in memory locations 0x100, 0x101, 0x102, and 0x103.

For ordering the bytes representing an object, there are two common conventions. 

Consider a w-bit integer having a bit representation ,
where x w−1 is the most significant bit and x 0 is the least. 

Assuming w is a multiple of 8, these bits can be grouped as bytes, 
with the most significant byte having bits , 
the least significant byte having bits,
 
and the other bytes having bits from the middle. 

Some machines choose to store the object in memory ordered from least significant byte to most, 

while other machines store them from most to least. The former convention—where the least 
significant byte comes first—is referred to as little endian. 

This convention is followed by most Intel-compatible machines. 

The latter convention—where the most significant byte comes first—is referred to as big endian. 

This convention is followed by most machines from IBM and Sun Micro systems. 

Note that we said “most.” The conventions do not split precisely along corporate boundaries. 

For example, both IBM and Sun manufacture machines that use Intel-compatible processors and hence are little endian. 

Many recent microprocessors are bi-endian, 
meaning that they can be configured to operate as either little- or big-endian machines.

Continuing our earlier example, suppose the variable x of type int and at address 0x100 has a hexadecimal value of 0x01234567. 

The ordering of the bytes within the address range 0x100 through 0x103 depends on the type of machine:

big endian little endian

Note that in the word 0x01234567 the high-order byte has hexadecimal value 0x01, 
while the low-order byte has value 0x67.

People get surprisingly emotional about which byte ordering is the proper one.

In fact, the terms “little endian” and “big endian” come from the book Gulliver’s Travels by Jonathan Swift, 

where two warring factions could not agree as to how a soft-boiled egg should be opened—by the little end or by the big. 
Just like the egg issue, 

there is no technological reason to choose one byte ordering convention over the other, 

and hence the arguments degenerate into bickering about socio-political issues. 

As long as one of the conventions is selected and adhered to consistently, the choice is arbitrary.

>Aside
Origin of “endian”
Here is how Jonathan Swift, writing in 1726, described the history of the controversy between big and little endians:

>. . . Lilliput and Blefuscu . . . have, as I was going to tell you, been engaged in a most obstinate war for six-and-thirty moons past. 
It began upon the following occasion. It is allowed on all hands, that the primitive way of breaking eggs, before we eat them, was upon the larger end; 
but his present majesty’s grandfather, while he was a boy, going to eat an egg, and breaking it according to the ancient practice, 
happened to cut one of his fingers. Whereupon the emperor his father published an edict, 
commanding all his subjects, upon great penalties, to break the smaller end of their eggs.
The people so highly resented this law, that our histories tell us, there have been six rebellions raised on that account; 
wherein one emperor lost his life, and another his crown. 
These civil commotions were constantly fomented by the monarchs of Blefuscu; and when they were quelled, 
the exiles always fled for refuge to that empire. It is computed that eleven thousand persons have at several times suffered death, 
rather than submit to break their eggs at the smaller end. 
Many hundred large volumes have been published upon this controversy: 
but the books of the Big-endians have been long forbidden, and the whole party rendered incapable by law of holding employments.

>In his day, Swift was satirizing the continued conflicts between England (Lilliput) and France (Blefuscu).
Danny Cohen, an early pioneer in networking protocols, first applied these terms to refer to byte ordering , and the terminology has been widely adopted.

For most application programmers, the byte orderings used by their machines are totally invisible; 

programs compiled for either class of machine give identical results. 

At times, however, byte ordering becomes an issue. 

The first is when binary data are communicated over a network between different machines. 

A common problem is for data produced by a little-endian machine to be sent to a big-endian machine, 
or vice versa, leading to the bytes within the words being in reverse order for the receiving program. 

To avoid such problems, code written for networking applications must follow established conventions for byte ordering to
make sure the sending machine converts its internal representation to the network standard, 

while the receiving machine converts the network standard to its internal representation. 

We will see examples of these conversions in Chapter 11.

A second case where byte ordering becomes important is when looking at the byte sequences representing integer data. 

This occurs often when inspecting machine-level programs. 

As an example, the following line occurs in a file that gives a text representation of the machine-level code for an Intel IA32 processor:

This line was generated by a disassembler, a tool that determines the instruction sequence represented by an executable program file. 

We will learn more about disassemblers and how to interpret lines such as this in Chapter 3. 

For now, we simply note that this line states that the hexadecimal byte sequence 01 05 64 94 04 08 is the byte-level representation of an instruction that 
adds a word of data to the value stored at address 0x8049464. 

If we take the final 4 bytes of the sequence, 64 94 04 08, and write them in reverse order, we have 08 04 94 64. 

Dropping the leading 0, we have the value 0x8049464, the numeric value written on the right. 

Having bytes appear in reverse order is a common occurrence when reading machine-level program representations generated for little-endian

Figure 2.4 Code to print the byte representation of program objects. 
This code uses casting to circumvent the type system. Similar functions are easily defined for other data types.

machines such as this one. The natural way to write a byte sequence is to have lowest-numbered byte on the left and the highest on the right, 

but this is contrary to the normal way of writing numbers with the most significant digit on the left and the least on the right.

A third case where byte ordering becomes visible is when programs are written that circumvent the normal type system. 

In the C language, this can be done using a cast to allow an object to be referenced according to a different data type from which it was created. 

Such coding tricks are strongly discouraged for most application programming, but they can be quite useful and even necessary for system-level programming.

Figure 2.4 shows C code that uses casting to access and print the byte representations of different program objects. 

We use typedef to define data type byte_pointer as a pointer to an object of type “unsigned char.” 

Such a byte pointer references a sequence of bytes where each byte is considered to be a non-negative integer. 

The first routine show_bytes is given the address of a sequence of bytes, indicated by a byte pointer, and a byte count. 

It prints the individual bytes in hexadecimal. 

The C formatting directive “%.2x” indicates that an integer should be printed in hexadecimal with at least two digits.


>New to C?
Naming data types with typedef
The typedef declaration in C provides a way of giving a name to a data type. 
This can be a great help in improving code readability, since deeply nested type declarations can be difficult to decipher.
The syntax for typedef is exactly like that of declaring a variable, 
except that it uses a type name rather than a variable name. 
Thus, the declaration of byte_pointer in Figure 2.4 has the same form as the declaration of a variable of type “unsigned char *.”
For example, the declaration typedef int *int_pointer; 
int_pointer ip;
defines type “int_pointer” to be a pointer to an int, 
and declares a variable ip of this type. Alternatively, we could declare this variable directly as int *ip;

>New to C?
Formatted printing with printf
The printf function (along with its cousins fprintf and sprintf) provides a way to print information with considerable control over the formatting details. 
The first argument is a format string, while any remaining arguments are values to be printed. Within the format string, 
each character sequence starting with ‘%’ indicates how to format the next argument. 
Typical examples include 
‘%d’ to print a decimal integer, 
‘%f’ to print a floating-point number, 
and ‘%c’ to print a character 
having the character code given by the argument.

>New to C?
Pointers and arrays
In function show_bytes (Figure 2.4), 
we see the close connection between pointers and arrays, 
as will be discussed in detail in Section 3.8. We see that this function has an argument start of type byte_pointer 
(which has been defined to be a pointer to unsigned char), 
but we see the array reference start[i] on line 8. 
In C, we can dereference a pointer with array notation, 
and we can reference array elements with pointer notation. 
In this example, the reference start[i] indicates that we want to read the byte that is i positions beyond the location pointed to by start.

Procedures show_int, show_float, and show_pointer demonstrate how to use procedure show_bytes to print the byte representations of C program objects of 
type int, float, and void *, respectively. 

Observe that they simply pass show_bytes a pointer &x to their argument x, casting the pointer to be of type “unsigned char *.” 

This cast indicates to the compiler that the program should consider the pointer to be to a sequence of bytes rather than to an object of the original data type. 

This pointer will then be to the lowest byte address occupied by the object.

>New to C?
Pointer creation and dereferencing
In lines 13, 17, and 21 of Figure 2.4, 
we see uses of two operations that give C (and therefore C++) its distinctive character. 
The C “address of” operator & creates a pointer. 
On all three lines, the expression &x creates a pointer to the location holding the object indicated by variable x. 
The type of this pointer depends on the type of x, 
and hence these three pointers are of type int *, float *, and void **, respectively. 
(Data type void * is a special kind of pointer with no associated type information.)
The cast operator converts from one data type to another. 
Thus, the cast (byte_pointer) &x indicates that whatever type the pointer &x had before, 
the program will now reference a pointer to data of type unsigned char. 
The casts shown here do not change the actual pointer; 
they simply direct the compiler to refer to the data being pointed to according to the new data type.


These procedures use the C sizeof operator to determine the number of bytes used by the object. 

In general, the expression sizeof(T ) returns the number of bytes required to store an object of type T . 

Using sizeof rather than a fixed value is one step toward writing code that is portable across different machine types.

We ran the code shown in Figure 2.5 on several different machines, giving the results shown in Figure 2.6. The following machines were used:
Linux 32:
Windows:
Sun:
Linux 64:
Intel IA32 processor running Linux
Intel IA32 processor running Windows
Sun Microsystems SPARC processor running Solaris
Intel x86-64 processor running Linux

Our argument 12,345 has hexadecimal representation 0x00003039. 

For the int data, we get identical results for all machines, except for the byte ordering. 

In particular, we can see that the least significant byte value of 0x39 is printed first for Linux 32, Windows, and Linux 64, indicating little-endian machines, 
and last for Sun, indicating a big-endian machine. 

Similarly, the bytes of the float data are identical, except for the byte ordering. 
On the other hand, the pointer values are completely different. 

The different machine/operating system configurations use different conventions for storage allocation. 

One feature to note is that the Linux 32, Windows, and Sun machines use 4-byte addresses, while the Linux 64 machine uses 8-byte addresses.

Observe that although the floating-point and the integer data both encode the numeric value 12,345, 

they have very different byte patterns: 0x00003039 for the integer, and 0x4640E400 for floating point. 

In general, these two formats use different encoding schemes. 

If we expand these hexadecimal patterns into binary form and shift them appropriately, 

we find a sequence of 13 matching bits, indicated by a sequence of asterisks, as follows: 

This is not coincidental. We will return to this example when we study floating-point formats.


