Representing Strings

A string in C is encoded by an array of characters terminated by the null (having value 0) character. 

Each character is represented by some standard encoding, 

with the most common being the ASCII character code. 

Thus, if we run our routine show_bytes with arguments "12345" and 6 (to include the terminating character),

we get the result 31 32 33 34 35 00. Observe that the ASCII code for decimal digit x happens to be 0x3x, 

and that the terminating byte has the hex representation 0x00. 

This same result would be obtained on any system using ASCII as its
character code, 

independent of the byte ordering and word size conventions. 

As a consequence, text data is more platform-independent than binary data.

>Aside
Generating an ASCII table
You can display a table showing the ASCII character code by executing the command man ascii.


>Aside
The Unicode standard for text encoding
The ASCII character set is suitable for encoding English-language documents, 
but it does not have much in the way of special characters, such as the French ‘ç.’ 
It is wholly unsuited for encoding documents in languages such as Greek, Russian, and Chinese. 
Over the years, a variety of methods have been developed to encode text for different languages. 
The Unicode Consortium has devised the most comprehensive and widely accepted standard for encoding text. 
The current Unicode standard (version 5.0) has a repertoire of nearly 100,000 characters supporting languages 
ranging from Albanian to Xamtanga (a language spoken by the Xamir people of Ethiopia).
The base encoding, known as the “Universal Character Set” of Unicode, uses a 32-bit representation of characters. 
This would seem to require every string of text to consist of 4 bytes per character.
However, alternative codings are possible where common characters require just 1 or 2 bytes, 
while less common ones require more. 
In particular, the UTF-8 representation encodes each character as a sequence of bytes, 
such that the standard ASCII characters use the same single-byte encodings as they have in ASCII, 
implying that all ASCII byte sequences have the same meaning in UTF-8 as they do in ASCII.
The Java programming language uses Unicode in its representations of strings. 
Program libraries are also available for C to support Unicode.


